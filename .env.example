# FFT_nano environment configuration (NO SECRETS)
#
# This file is a template. Copy to .env and fill in your own values.
# The host process reads .env and passes an allowlisted subset into the agent
# container (see src/container-runner.ts).

# ----------------------
# Channels
# ----------------------

# WhatsApp: enabled by default when set to 1.
# If using Telegram only (recommended for dev): set WHATSAPP_ENABLED=0
WHATSAPP_ENABLED=0

# Telegram: enable by setting a bot token
# TELEGRAM_BOT_TOKEN=123456:ABCDEF...

# Optional: make a specific Telegram chat the main/admin channel
# TELEGRAM_MAIN_CHAT_ID=123456789

# Optional: allow claiming the main chat by DMing /main <secret>
# TELEGRAM_ADMIN_SECRET=change-me

# Optional: max size (MB) for inbound Telegram media persisted to groups/<group>/inbox/telegram
# TELEGRAM_MEDIA_MAX_MB=20

# ----------------------
# Container runtime
# ----------------------

# auto (default): prefers Apple Container on macOS when available, else Docker
# CONTAINER_RUNTIME=auto

# Agent image (built by ./container/build.sh or ./container/build-docker.sh)
# CONTAINER_IMAGE=fft-nano-agent:latest

# ----------------------
# Pi runtime (LLM provider)
# ----------------------

# Option A (recommended for "free/local" compute): OpenAI-compatible local endpoint
# Examples: Ollama (OpenAI-compatible proxy), llama.cpp server, vLLM, etc.
PI_API=openai
OPENAI_BASE_URL=http://localhost:11434/v1
OPENAI_API_KEY=local
# PI_MODEL=your-model-name

# Option B: Z.AI (GLM)
# PI_API=zai
# PI_MODEL=glm-4.7
# ZAI_API_KEY=...

# Option C: Anthropic API key
# PI_API=anthropic
# PI_MODEL=claude-3-5-sonnet-latest
# ANTHROPIC_API_KEY=...

# Option D: OpenAI hosted
# PI_API=openai
# PI_MODEL=gpt-4o-mini
# OPENAI_API_KEY=...

# ----------------------
# Debug
# ----------------------
# LOG_LEVEL=debug
# FFT_NANO_DRY_RUN=1
